{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "MAE_DIR = '/home/neelamlab/ninad/MAE'\n",
    "ROOT_DIR = '/data/ninad/DATASET_linear'\n",
    "LABEL_DIR = f'/data/ninad/Metadata'\n",
    "RESULT_DIR = f'{MAE_DIR}/results'\n",
    "LOG_DIR = f'{MAE_DIR}/logs/'\n",
    "TASK = 'regression'\n",
    "CDRGLOB = 0.0\n",
    "ONLY_3T_SCANS = 0.001\n",
    "\n",
    "NP_SEED = 42\n",
    "TORCH_SEED = 36\n",
    "np.random.seed(NP_SEED)\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "LOGGER = setup_logger(logs_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFCN_seed_12\n",
      "results/SFCN_seed_12/fold_0/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_12/fold_1/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_12/fold_2/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_12/fold_3/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_12/fold_4/test_predictions_TEST_DATA.csv\n",
      "SFCN_seed_15\n",
      "results/SFCN_seed_15/fold_0/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_15/fold_1/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_15/fold_2/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_15/fold_3/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_15/fold_4/test_predictions_TEST_DATA.csv\n",
      "SFCN_seed_11\n",
      "results/SFCN_seed_11/fold_0/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_11/fold_1/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_11/fold_2/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_11/fold_3/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_11/fold_4/test_predictions_TEST_DATA.csv\n",
      "SFCN_seed_14\n",
      "results/SFCN_seed_14/fold_0/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_14/fold_1/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_14/fold_2/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_14/fold_3/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_14/fold_4/test_predictions_TEST_DATA.csv\n",
      "SFCN_seed_13\n",
      "results/SFCN_seed_13/fold_0/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_13/fold_1/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_13/fold_2/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_13/fold_3/test_predictions_TEST_DATA.csv\n",
      "results/SFCN_seed_13/fold_4/test_predictions_TEST_DATA.csv\n"
     ]
    }
   ],
   "source": [
    "RESULT_DIR = 'results'\n",
    "filename = 'test_predictions_TEST_DATA.csv'\n",
    "runmetrics = {}\n",
    "age_threshold = 0\n",
    "MIN_SEED = 11\n",
    "MAX_SEED = 15\n",
    "SKIP_SEED = 20\n",
    "for run in os.listdir(RESULT_DIR):\n",
    "    if run[:4]=='SFCN' and MIN_SEED<=int(run.split('_')[-1])<=MAX_SEED and int(run.split('_')[-1])!=SKIP_SEED:\n",
    "        print(run)\n",
    "        for fold in range(5):\n",
    "            print(os.path.join(RESULT_DIR, run, f'fold_{fold}',filename))\n",
    "            # runmetrics[run] = {}\n",
    "            if os.path.exists(os.path.join(RESULT_DIR, run, f'fold_{fold}',filename)):\n",
    "                true, predicted = [],[]\n",
    "                for dataset_name, _, i,j in pd.read_csv(os.path.join(RESULT_DIR, run, f'fold_{fold}', filename)).values:\n",
    "                    if True: #dataset_name == 'CBR': #dataset_name != 'CBR' and dataset_name != 'LASI': #dataset_name == 'CBR': #\n",
    "                        if i < age_threshold:\n",
    "                            continue\n",
    "                        true.append(i)\n",
    "                        predicted.append(j)\n",
    "                # plot_brain_age_delta(true, predicted, name=f'{run} TEST')\n",
    "                runmetrics[f'{run}_f{fold}'] = {}\n",
    "                runmetrics[f'{run}_f{fold}']['F1'] = f1_score(true,predicted)\n",
    "                runmetrics[f'{run}_f{fold}']['Acc'] = accuracy_score(true,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SFCN_seed_12_f0</th>\n",
       "      <td>0.945813</td>\n",
       "      <td>0.937143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFCN_seed_12_f1</th>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFCN_seed_12_f2</th>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.937143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFCN_seed_12_f3</th>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.937143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFCN_seed_12_f4</th>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.931429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F1       Acc\n",
       "SFCN_seed_12_f0  0.945813  0.937143\n",
       "SFCN_seed_12_f1  0.948454  0.942857\n",
       "SFCN_seed_12_f2  0.943005  0.937143\n",
       "SFCN_seed_12_f3  0.942408  0.937143\n",
       "SFCN_seed_12_f4  0.940594  0.931429"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(runmetrics).T\n",
    "mean_values = df.mean().round(4)\n",
    "std_values = df.std().round(4)\n",
    "mean_std = mean_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "# df.loc['mean ± std'] = mean_std\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               F1_mean    F1_std  Acc_mean   Acc_std\n",
      "Seed                                                \n",
      "SFCN_seed_11  0.927080  0.018121  0.923429  0.015959\n",
      "SFCN_seed_12  0.944055  0.003091  0.937143  0.004041\n",
      "SFCN_seed_13  0.942291  0.005407  0.934857  0.005111\n",
      "SFCN_seed_14  0.907314  0.007806  0.890286  0.012388\n",
      "SFCN_seed_15  0.915475  0.010108  0.902857  0.014569\n"
     ]
    }
   ],
   "source": [
    "df['Seed'] = df.index.to_series().apply(lambda x: '_'.join(x.split('_')[:3]))\n",
    "summary_df = df.groupby('Seed').agg({'F1': ['mean', 'std'], 'Acc': ['mean', 'std']})\n",
    "summary_df.columns = ['_'.join(col) for col in summary_df.columns]\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Fieldmapdata_4updated(Dataset):\n",
    "    def __init__(self, root_dir, label_dir, task='classification'):\n",
    "        self.labels_df = self.load_labels(label_dir)\n",
    "        self.samples = self.make_dataset(root_dir, task=task)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getposweight__(self):\n",
    "        sexs = []\n",
    "        for paths, sex in self.samples:\n",
    "            sexs.append(sex)\n",
    "        return sum(sexs) / (len(sexs) - sum(sexs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_paths, label, dataset, id_ = self.samples[idx]\n",
    "        nifti_tensors = []\n",
    "        for img_path in img_paths:\n",
    "            nifti_data = nib.load(img_path)\n",
    "            data = nifti_data.get_fdata()\n",
    "            nifti_tensors.append(torch.tensor(data, dtype=torch.float32))\n",
    "        \n",
    "        image_tensor = torch.stack(nifti_tensors, dim=0)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "        label_tensor = (label_tensor, dataset, id_)\n",
    "        return image_tensor, label_tensor\n",
    "       \n",
    "    def make_dataset(self, root_dir, task='regression'):\n",
    "        samples = []\n",
    "        labels_df = self.labels_df\n",
    "\n",
    "        # Define subdirectories corresponding to the four fieldmaps\n",
    "        subdirs = ['AD', 'RD', 'ADC', 'FA']\n",
    "\n",
    "        # Collect subject IDs and their corresponding fieldmap paths\n",
    "        subject_files = {}\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            for fname in os.listdir(subdir_path):\n",
    "                if fname.endswith(\".nii.gz\") or fname.endswith(\".nii\"):\n",
    "                    id_ = self.extract_id_from_filename(fname)\n",
    "                    path = os.path.join(subdir_path, fname)\n",
    "                    if id_ not in subject_files:\n",
    "                        subject_files[id_] = {}\n",
    "                    subject_files[id_][subdir] = path\n",
    "\n",
    "        # Ensure each subject has all four fieldmaps\n",
    "        for id_, paths_dict in subject_files.items():\n",
    "            if all(subdir in paths_dict for subdir in subdirs):  # Check if all four fieldmaps are present\n",
    "                try:\n",
    "                    paths = [paths_dict[subdir] for subdir in subdirs]  # Ordered list of paths\n",
    "                    if task == 'regression': \n",
    "                        label = labels_df[labels_df['Subject'] == id_]['Age'].iloc[0]\n",
    "                    else:\n",
    "                        label = labels_df[labels_df['Subject'] == id_]['Gender'].iloc[0]\n",
    "                    samples.append((paths, label, 'HCP', id_))\n",
    "                except Exception:\n",
    "                    continue\n",
    "        return samples\n",
    "    \n",
    "    def extract_id_from_filename(self, fname):\n",
    "        fname = fname.replace(\"sub-\",\"\")\n",
    "        if fname.endswith(\"_ad.nii.gz\"):\n",
    "            id_ = fname.replace(\"_ad.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_rd.nii.gz\"):\n",
    "            id_ = fname.replace(\"_rd.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_adc.nii.gz\"):\n",
    "            id_ = fname.replace(\"_adc.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_fa.nii.gz\"):\n",
    "            id_ = fname.replace(\"_fa.nii.gz\", \"\")\n",
    "        elif fname.endswith(\".nii.gz\"):\n",
    "            id_ = fname.replace(\".nii.gz\", \"\")\n",
    "        return id_\n",
    "\n",
    "    def load_labels(self, label_path):\n",
    "        df = pd.read_csv(label_path)\n",
    "        df_filtered = df[['Subject', 'Gender', 'Age']].copy()\n",
    "        df_filtered['Gender'] = df_filtered['Gender'].map({'M': 0, 'F': 1}).astype(int)\n",
    "        df_filtered['Age'] = df_filtered['Age'].apply(lambda x: (int(x.split('-')[0]) + int(x.split('-')[1])) // 2 if '-' in x else int(x[:-1])).astype(float)\n",
    "        df_filtered['Subject'] = df_filtered['Subject'].astype(str)\n",
    "        return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Fieldmapdata_4updated(root_dir='/data/ninad/fieldmaps/',label_dir='/data/ninad/fieldmaps/HCPCN2mm.csv')\n",
    "a.__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ninad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
